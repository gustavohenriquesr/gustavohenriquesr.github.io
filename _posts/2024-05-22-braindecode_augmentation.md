---
title: First contribution to Braindecode - Add new augmentation method (SegmentationReconstruction)
date: 2024-05-22
categories: [Braindecode, Open-Science, MAC5856 - Desenvolvimento de Software Livre]
tags: [open source, open science]     # TAG names should always be lowercase
comments: false
math: true
---

Comments on my contribution to braindecode, adding a new augmentation method called SegmentationReconstruction.

<!--
Recentemente, eu escrevi junto ao meu orientador e colega [Bruno Aristimunha](https://github.com/bruAristimunha) um paper a partir de alguns resultados que obtive na minha pesquisa de iniciação científica na graduação. Neste paper, o qual estou feliz em poder dizer que foi aprovado para a conferência EUSIPICO 2024 e poderá ser publicado futuramente, eu trabalho com o uso de técnicas que permitem usufruir de uma maior quantidade de dados para treinamento de modelos de aprendizado profundo no contexto de eletroencefalografia (EEG). As técnicas com as quais eu trabalhei foram alinhamento euclidiano, de forma a aproximar os domínios em que os dados de cada sujeito no dataset se encontram e provocar maior similaridade entre estes e, uma nova forma de aumentação de dados, chamada Segmentação & Reconstrução (S&R), pouco explarada no contexto em que me insiro.

No contexto da minha pesquisa, em que trabalho com dados de EEG, para facilitar o manuseio de processamento de dados e utilização de classificardores, entre outros casos, eu utilizo ostensivamente o [Braindecode](https://braindecode.org/stable/index.html), uma biblioteca open-source para interfaces cérebro-computador (BCI) focada em implementar as principais ferramentas para manusear dados neurais, como processamentos, carregadores de dados, modelos publicados, entre outras coisas. Uma vez que no paper eu propus a utilização da aumentação de dados S&R, e os resultado indicados no paper se mostraram positivos (obtendo uma melhora de até 8.58% na acurácia de teste), decidi por incluir esta técnica no acervo de aumentações que o Braindecode fornece para dados de BCI.
-->

Recently, I wrote a [paper](https://arxiv.org/abs/2405.14994) along with my advisor and colleagues based on some of the results I obtained in my undergraduate research. In this paper, which I am happy to say has been accepted for the [EUSIPICO 2024](https://eusipcolyon.sciencesconf.org/) conference, I work on the use of techniques that allow us to take advantage of a larger amount of data to train deep learning models in the context of electroencephalography (EEG). The techniques I've worked with are Euclidean alignment, in order to bring together the domains in which the data of each subject in the dataset are found, with the intention to cause greater similarity between them, and a new form of data augmentation, called Segmentation & Reconstruction (S&R), which is poorly explored in the field of EEG.

In the context of my research, in which I work with EEG data, to facilitate the handling of data processing and the use of classifiers, among other cases, I make extensive use of [Braindecode](https://braindecode.org/stable/index.html), an open-source library for brain-computer interfaces (BCI) focused on implementing the main tools for handling neural data, such as processing, data loaders, published models, among other things. Since in the paper I proposed the use of S&R data augmentation, and the results indicated in the paper proved to be positive (obtaining an improvement of up to 8.58% in test accuracy), I decided to include this technique in the collection of augmentations that Braindecode provides for BCI data.
### About data augmentation (S&R)

<!--
Primeiramente, para aqueles que não estejam familiarizados com o conceito de aumentação de dados em machine learning, esse processo consiste no aumento do conjunto de dados de treino de um modelo. Isso é feito ao se adicionar novos exemplos sintéticos a partir da transformação dos dados disponíveis enquanto preservamos as labels. Dessa forma, podemos aliviar o problema de overfitting e promovemos regularização do modelo uma vez que redes neurais se tornam invariantes com as transformações impostas pela técnica. Mais sobre aumentação de dados pode ser visto nesta [publicação](https://aws.amazon.com/pt/what-is/data-augmentation/#:~:text=Deep%20learning%20models%20rely%20on,data%20is%20vital%20in%20training.).

No contexto de decodificação de EEG, devido à propriedade não estacionária presente nos sinais (reflexo do comportamento neural de uma pessoa), os segmentos mais importantes de um sinal de EEG não possuem um tamanho ou um ponto fixo no domínio temporal. Dessa forma, para aproveitar essa propriedade e introduzir maior variabilidade à rede neural, utilizamos a estratégia de segmentação e reconstrução de sinais como um método de aumentação de dados. A técnica é feita, portanto, da seguinte forma: dados um sinal $x$ com dimensões $C x T$ para cada classe, nós segmentamos a componente temporal em $s$ partes. Então, através do conjunto de trials para cada classe, nós concatenamos de forma aleatória esses segmentos para formar novos trials sintéticos reconstruídos, mantendo a ordem temporal original. A imagem abaixo ilustra como o processo é realizado nos dados e foi retirada do [artigo original](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7109822) que propôs e inspirou a implementação da estratégia.
-->
First of all, for those unfamiliar with the concept of data augmentation in machine learning, this process consists of increasing the training data set of a model. This is done by adding new synthetic examples by transforming the available data while preserving the labels. In this way, we can alleviate the problem of overfitting and promote regularization of the model since neural networks become invariant with the transformations imposed by the technique. More on data augmentation can be seen in this [publication](https://aws.amazon.com/pt/what-is/data-augmentation/#:~:text=Deep%20learning%20models%20rely%20on,data%20is%20vital%20in%20training.).

In the context of EEG decoding, due to the non-stationary property present in signals (a reflection of a person's neural behavior), the most important segments of an EEG signal do not have a fixed size or point in the time domain. Therefore, in order to take advantage of this property and introduce greater variability into the neural network, we used the strategy of segmenting and reconstructing signals as a data augmentation method. The technique performs the following process: given a signal $x$ with dimensions $C \times T$ for each label, with $C$ as the number of channels (electrodes), $T$ is the number of time points in the matrices and $i ∈$ {$1 . . . N$} are in the index vector, with $N$ as the total number of trials/matrices, we segment the temporal component into $s$ parts. Then, using the set of trials for each label, we randomly concatenate these segments to form new reconstructed synthetic trials, maintaining the original temporal order. The image below illustrates how the process is carried out on the data and was taken from the [original article](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7109822) that proposed and inspired the implementation of the strategy.

![Data Augmentation](assets/img/data_augmentation.png)
_Principle of generating new EEG data artificially using the Segmentation and Reconstruction technique in the time domain._

### Process of integration in Braindecode
<!--
Para integração da técnica ao Braindecode, eu abri um [Pull Request](https://github.com/braindecode/braindecode/pull/608) solicitando a adição de uma nova estratégia de aumentação de dados. Seguindo o estilo de implementação do Braindecode, meu código se baseou em dois arquivos principais: `transforms.py` e `functional.py`, uma para lidar com a técnica a nível de classe, a qual é chamada pelo dataloader e pelo classificador, e outra, como o próprio nome diz, funcional, a qual trabalha diretamente com os dados para transformação, respectivamente. Após fazer o código e implementar alguns testes para verificação, enviei para revisão no PR e obtive feedback prontamente. 

As revisões em geral visavam adequar o código ao estilo da biblioteca e principalmente lidar com os diversos egde cases que podem surgir nos mais diferentes tipos de treinamento de modelos que possam se aproveitar desta técnica. Todavia, entre as alterações pedidas pelos revisores houve três que merecem mais destaque. 

A primeira se referia a um erro que estava ocorrendo com o uso da aumentação no contexto do classificador (usando diretamente nos dados estava funcionando perfeitamente). Por mais bobo que pareça, os erros simples que alteram uma ou poucas linhas de código parecem ser os mais difíceis de se encontrar e consertar, e foi dessa forma que ocorreu. Depois de algum tempo quebrando a cabeça, descobri que o problema estava na indexação das classes dos dados fornecidos, que ocorria somente no uso do classificador que controla a probabilidade da aumentação ser aplicada ou não. Resolvido esse problema, o código voltou a funcionar como deveria. 

A segunda alteração por outro lado envolvia otimização computacional, uma vez que a primeira versão continha laços for aninhados para varrer cada trial e cada segmento desses trials. Com algumas modificações utilizando algumas propriedades de arrays [numpy](https://numpy.org/) fui capaz de suprimir um dos laços e melhorar o funcionamento da transformação. 

Por fim, a terceira alteralção estava relacionada à preferência de estilo de organização do código. Nesse caso, foi sugerido que todas as partes do código que envolvessem amostragens aleatórias fossem levadas para o nível de classe, e que somente ações determísticas ficassem no contexto funcional. Isso se devia à uma preferência organizacional para que o Braindecode seguisse a padronização feita pelo [torchvision](https://pytorch.org/vision/stable/index.html), um pacote para transformações de imagens para modelos de visão computacional. Em um primeiro momento, depois de algumas tentativas, acreditei que não seria possível fazer tal alteração devido justamente aos laços for do código, que permeiam o parte principal da transformação. Assim, a única forma que vi para realizar a alteração era fazendo com que todo funcional fosse levado para o nível de classe, o que não fazia muito sentido para mim. Depois de deixar esse problema de lado por algumas horas e preparado para escrever que não era possível resolvê-lo para os revisores, decidi tentar mais uma vez. De alguma forma, consegui dividir o código funcional levando partes que envolviam amostragem aleatória para o nível de classe e preservei o parte principal da transformação na parte funcional, somente com operações determinísticas. Para esses ajustes, tive de adicionar algumas redundâncias no código mas que se mostraram robustas e que não parecem ter afetado significativemente no que se refere à otimização do processamento. 

Com todas as alterações solicitadas feitas, pedi novamente por uma revisão e finalmente meu PR foi aceito e mergeado para a branch master do Braindecode. A técnica S&R já pode ser utilizada através da biblioteca na sua versão de desenvolvimento e pode ser encontrada [aqui](https://braindecode.org/dev/generated/braindecode.augmentation.SegmentationReconstruction.html) e em breve estará na release da próxima versão oficial. Estou muito satisfeito com a contribuição e agradeço aos revisores que me ajudaram gentilmente no processo de integração. Espero que futuramente possa fazer novas contribuições. 
-->

To integrate the technique into Braindecode, I opened a [Pull Request](https://github.com/braindecode/braindecode/pull/608) for the addition of a new data augmentation strategy. Following Braindecode's implementation style, my code was based on two main files: `transforms.py` and `functional.py`, one to handle the technique at class level, which is called by the dataloader and classifier, and the other, as the name implies, functional, which works directly with the data for transformation, respectively. After making the code and implementing some tests for verification, I sent it to PR for review and received feedback promptly. 

The revisions were generally aimed at adapting the code to the style of the library and, above all, dealing with the various egde cases that can arise in the most different types of model training that can take advantage of this technique. However, among the changes requested by the reviewers, there were three that deserve to be highlighted. 

The first referred to an error that was occurring with the use of augmentation in the context of the classifier (using it directly on the data was working perfectly). As silly as it sounds, simple errors that change one or a few lines of code seem to be the hardest to find and fix, and that's how it happened. After several tests, I discovered that the problem was in the indexing of the labels of the data provided, which only occurred when using the classifier that controls the probability of the augmentation being applied or not. Once this problem was solved, the code worked as it should again. 

The second change, on the other hand, involved computational optimization, since the first version contained nested 'for' loops to scan each trial and each segment of those trials. With a few modifications using some properties of [numpy](https://numpy.org/) arrays, I was able to remove one of the loops and improve the operation of the transformation. 

Finally, the third change was related to the code style preference. In this case, it was suggested that all parts of the code involving random sampling should be taken to the class level, and that only deterministic actions should remain in the functional context. This was due to an organizational preference for Braindecode to follow the standardization made by [torchvision](https://pytorch.org/vision/stable/index.html), a package for image transformations for computer vision models. At first, after a few attempts, I thought it wouldn't be possible to make such a change, precisely because of the 'for' loops in the code, which permeate the main part of the transformation. So the only way I could see to make the change was to take every functional to the class level, which didn't make much sense to me. After putting this problem aside for a time and prepared to write that it couldn't be solved for the reviewers, I decided to give it one more try. Somehow, I managed to split the functional code by taking parts that involved random sampling down to the class level and preserved the main part of the transformation in the functional part, only with deterministic operations. For these adjustments, I had to add some redundancies in the code, but they proved to be robust and don't seem to have significantly affected processing optimization. 

With all the requested changes made, I asked again for a review and finally my PR was accepted and merged into the Braindecode master branch. The S&R technique can now be used through the library in its development version and can be found [here](https://braindecode.org/dev/generated/braindecode.augmentation.SegmentationReconstruction.html) and will soon be in the release of the next official version. I'm very pleased with the contribution and thank the reviewers who kindly helped me with the integration process. I hope to be able to make further contributions in the future. 

